import os
import datetime
from ..flow_manager import flow

class StateGenerateCoverageReport():
    def __init__(self):
        print("Initializing [StateGenerateCoverageReport]")

    def run(self, input_data):
        flow.transition("StateGenerateCoverageReport")
        print("[StateGenerateCoverageReport] Generating coverage report...")
        
        # Get project information
        cmake_dir = input_data.get_input_data()
        project_name = os.path.basename(cmake_dir)
        
        # Create report content
        report_content = self._generate_report_content(input_data, project_name, cmake_dir)
        
        # Save report to output folder
        output_dir = "output/UnitTestCoverage"
        report_file = os.path.join(output_dir, "coverage_report.txt")
        
        try:
            with open(report_file, 'w') as f:
                f.write(report_content)
            print(f"[StateGenerateCoverageReport] Coverage report saved to: {report_file}")
            return True, input_data
        except Exception as e:
            print(f"[StateGenerateCoverageReport] Error writing report: {e}")
            return False, input_data

    def _generate_report_content(self, input_data, project_name, cmake_dir):
        """Generate comprehensive coverage report content"""
        
        # Header
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        report = f"""
{'='*80}
           C++ MICRO AGENT - COVERAGE ANALYSIS REPORT
{'='*80}

Project Name: {project_name}
Project Path: {cmake_dir}
Generated:    {timestamp}
Analysis Type: states_coverage (Unit Test Generation)

{'='*80}
"""

        # Source Files Analysis
        source_files = input_data.get_source_files()
        report += f"""
SOURCE FILES ANALYSIS
{'='*40}

Total Source Files Discovered: {len(source_files)}

Source Files:
"""
        for i, source_file in enumerate(source_files, 1):
            report += f"  {i:2d}. {source_file}\n"

        # Include Directories Analysis
        include_dirs = input_data.get_include_folders()
        report += f"""

INCLUDE DIRECTORIES ANALYSIS
{'='*40}

Total Header Files Discovered: {len(include_dirs)}

Header Files:
"""
        for i, header_file in enumerate(include_dirs, 1):
            header_name = os.path.basename(header_file)
            header_dir = os.path.dirname(header_file).replace(cmake_dir, ".")
            report += f"  {i:2d}. {header_name:<25} ({header_dir})\n"

        # Function Coverage Analysis
        report += self._analyze_function_coverage()

        # Mock Generation Analysis
        report += self._analyze_mock_generation()

        # Code Coverage Analysis (lcov/gcov)
        report += self._analyze_code_coverage(input_data)

        # Iterative Coverage Improvement Results
        report += self._analyze_iterative_coverage_results(input_data)

        # Recommendations
        report += self._generate_recommendations(len(source_files), len(include_dirs), input_data)

        # Footer
        report += f"""

{'='*80}
Report generated by C++ Micro Agent - states_coverage
For questions or issues, check the documentation.
{'='*80}
"""
        return report

    def _analyze_function_coverage(self):
        """Analyze generated function coverage"""
        
        output_dir = "output/UnitTestCoverage"
        if not os.path.exists(output_dir):
            return "\nFUNCTION COVERAGE ANALYSIS\n" + "="*40 + "\n\nNo coverage data available.\n"

        report = f"""
FUNCTION COVERAGE ANALYSIS
{'='*40}

"""
        
        total_functions = 0
        total_classes = 0
        files_processed = 0
        
        # Walk through the output directory
        for root, dirs, files in os.walk(output_dir):
            if root == output_dir:  # Skip the root directory
                continue
                
            # Count source file directories
            if root.count(os.sep) - output_dir.count(os.sep) == 1:
                files_processed += 1
                source_file = os.path.basename(root)
                report += f"\nğŸ“ {source_file}:\n"
                
                # Count functions in this source file
                function_count = 0
                class_count = 0
                
                for subdir in dirs:
                    function_path = os.path.join(root, subdir)
                    if os.path.isdir(function_path):
                        if "::" in subdir:  # Class method
                            class_name = subdir.split("::")[0]
                            method_name = subdir.split("::")[-1]
                            report += f"   ğŸ”§ {class_name}::{method_name}\n"
                            class_count += 1 if method_name not in ["constructor", "destructor"] else 0
                        else:  # Free function
                            report += f"   âš¡ {subdir}()\n"
                        function_count += 1
                
                total_functions += function_count
                total_classes += 1 if class_count > 0 else 0
                report += f"   â””â”€ Functions: {function_count}\n"

        report += f"""
SUMMARY:
--------
ğŸ“Š Source Files Processed: {files_processed}
ğŸ”§ Total Functions Found:   {total_functions}
ğŸ“¦ Classes Identified:     {total_classes}
ğŸ“‹ Mock Headers Generated: {self._count_mock_headers()}

"""
        return report

    def _count_mock_headers(self):
        """Count generated mock header files"""
        count = 0
        output_dir = "output/UnitTestCoverage"
        
        if os.path.exists(output_dir):
            for root, dirs, files in os.walk(output_dir):
                count += len([f for f in files if f.endswith('.h')])
        
        return count

    def _analyze_mock_generation(self):
        """Analyze mock generation results"""
        
        mock_count = self._count_mock_headers()
        
        report = f"""
MOCK GENERATION ANALYSIS
{'='*40}

Total Mock Headers Generated: {mock_count}

"""
        
        if mock_count > 0:
            output_dir = "output/UnitTestCoverage"
            mock_files = []
            
            for root, dirs, files in os.walk(output_dir):
                for file in files:
                    if file.endswith('.h'):
                        rel_path = os.path.relpath(os.path.join(root, file), output_dir)
                        mock_files.append(rel_path)
            
            report += "Generated Mock Files:\n"
            for i, mock_file in enumerate(sorted(mock_files), 1):
                report += f"  {i:2d}. {mock_file}\n"
        else:
            report += "No mock headers were generated.\n"
        
        return report

    def _analyze_code_coverage(self, input_data):
        """Analyze lcov/gcov coverage results"""
        
        coverage_data = input_data.get_coverage_data()
        
        report = f"""
CODE COVERAGE ANALYSIS (LCOV/GCOV)
{'='*40}

"""
        
        if not coverage_data:
            report += "No coverage data available. Coverage analysis was not performed.\n"
            return report
        
        if "error" in coverage_data:
            report += f"Coverage analysis failed: {coverage_data['error']}\n"
            return report
        
        # Overall coverage statistics
        coverage_pct = coverage_data.get("coverage_percentage", 0.0)
        lines_covered = coverage_data.get("lines_covered", 0)
        lines_total = coverage_data.get("lines_total", 0)
        functions_covered = coverage_data.get("functions_covered", 0)
        functions_total = coverage_data.get("functions_total", 0)
        
        report += f"Overall Coverage: {coverage_pct:.1f}%\n\n"
        
        # Coverage breakdown
        report += "Coverage Breakdown:\n"
        report += f"  ğŸ“Š Lines:     {lines_covered:4d}/{lines_total:<4d} ({coverage_pct:.1f}%)\n"
        
        if functions_total > 0:
            func_pct = (functions_covered / functions_total) * 100
            report += f"  ğŸ”§ Functions: {functions_covered:4d}/{functions_total:<4d} ({func_pct:.1f}%)\n"
        
        # Coverage assessment
        if coverage_pct >= 80:
            assessment = "âœ… Excellent"
            emoji = "ğŸŸ¢"
        elif coverage_pct >= 60:
            assessment = "ğŸŸ¡ Good"
            emoji = "ğŸŸ¡"
        elif coverage_pct >= 40:
            assessment = "ğŸŸ  Fair"
            emoji = "ğŸŸ "
        else:
            assessment = "ğŸ”´ Poor"
            emoji = "ğŸ”´"
        
        report += f"\nCoverage Assessment: {emoji} {assessment}\n"
        
        # Coverage files information
        gcov_files = coverage_data.get("gcov_files", [])
        if gcov_files:
            report += f"\nGenerated Coverage Files:\n"
            report += f"  ğŸ“ .gcov files: {len(gcov_files)} files generated\n"
            
            # Show first few gcov files as examples
            for i, gcov_file in enumerate(gcov_files[:3]):
                filename = os.path.basename(gcov_file)
                report += f"     â€¢ {filename}\n"
            
            if len(gcov_files) > 3:
                report += f"     â€¢ ... and {len(gcov_files) - 3} more\n"
        
        # LCOV HTML report
        lcov_html_dir = coverage_data.get("lcov_html_dir")
        if lcov_html_dir:
            report += f"\nğŸ“Š HTML Coverage Report:\n"
            report += f"  ğŸ“‚ Location: {lcov_html_dir}\n"
            report += f"  ğŸŒ Open: {os.path.join(lcov_html_dir, 'index.html')}\n"
        
        # Build information
        build_dir = coverage_data.get("build_dir")
        if build_dir:
            report += f"\nğŸ”¨ Build Information:\n"
            report += f"  ğŸ“‚ Build directory: {build_dir}\n"
            report += f"  âš™ï¸  Compiled with: --coverage -g -O0\n"
        
        # Detailed gcov output (if available and not too long)
        gcov_output = coverage_data.get("gcov_output", "")
        if gcov_output and len(gcov_output) < 2000:  # Only include if not too verbose
            report += f"\nDetailed GCOV Output:\n"
            report += "-" * 30 + "\n"
            report += gcov_output[:1000]  # Limit to first 1000 chars
            if len(gcov_output) > 1000:
                report += "\n... (output truncated)\n"
            report += "-" * 30 + "\n"
        
        return report

    def _analyze_iterative_coverage_results(self, input_data):
        """Analyze results from iterative coverage improvement"""
        
        iteration_results = input_data.get_coverage_iteration_results()
        
        report = f"""
ITERATIVE COVERAGE IMPROVEMENT RESULTS
{'='*40}

"""
        
        if not iteration_results:
            report += "No iterative coverage improvement was performed.\n"
            return report
        
        final_coverage = iteration_results.get("final_coverage", 0.0)
        iterations = iteration_results.get("iterations_completed", 0)
        target_achieved = iteration_results.get("target_achieved", False)
        target_coverage = iteration_results.get("target_coverage", 80.0)
        
        # Overall results
        status_emoji = "âœ…" if target_achieved else "ğŸ”„"
        status_text = "SUCCESS" if target_achieved else "IN PROGRESS"
        
        report += f"Status: {status_emoji} {status_text}\n"
        report += f"Target Coverage: {target_coverage}%\n"
        report += f"Final Coverage:  {final_coverage:.1f}%\n"
        report += f"Iterations:      {iterations}\n\n"
        
        # Coverage improvement analysis
        if target_achieved:
            report += f"ğŸ¯ Target coverage of {target_coverage}% achieved in {iterations} iteration(s)!\n"
            report += "âœ… Unit tests have been optimized for high coverage.\n"
        else:
            coverage_gap = target_coverage - final_coverage
            report += f"ğŸ“Š Coverage improved through {iterations} iterations.\n"
            report += f"âš ï¸  Still {coverage_gap:.1f}% away from target coverage.\n"
            
            if iterations >= 3:  # Max iterations reached
                report += "ğŸ”„ Maximum iterations reached. Consider:\n"
                report += "   - Manual test case addition\n"
                report += "   - Code refactoring for testability\n"
                report += "   - Review of unreachable code paths\n"
        
        # Iteration-by-iteration breakdown
        report += f"\nIteration Progress:\n"
        for i in range(1, iterations + 1):
            if i == 1:
                report += f"  Iteration {i}: Initial baseline measurement\n"
            else:
                report += f"  Iteration {i}: Regenerated tests with coverage feedback\n"
        
        # Unit test generation summary
        unit_tests_dir = "output/UnitTestCoverage/unit_tests"
        if os.path.exists(unit_tests_dir):
            test_files = [f for f in os.listdir(unit_tests_dir) if f.endswith('.cpp')]
            report += f"\nGenerated Unit Tests: {len(test_files)} files\n"
            
            for test_file in sorted(test_files):
                report += f"   â€¢ {test_file}\n"
        
        # Quality assessment
        if final_coverage >= 90:
            quality = "ğŸŸ¢ Excellent"
        elif final_coverage >= 80:
            quality = "ğŸŸ¡ Good"
        elif final_coverage >= 60:
            quality = "ğŸŸ  Fair"
        else:
            quality = "ğŸ”´ Needs Improvement"
        
        report += f"\nTest Quality Assessment: {quality}\n"
        
        return report

    def _generate_recommendations(self, source_count, header_count, input_data):
        """Generate recommendations based on analysis"""
        
        report = f"""
RECOMMENDATIONS
{'='*40}

"""
        
        if source_count == 0:
            report += "âš ï¸  No source files found. Check CMakeLists.txt configuration.\n"
        elif source_count < 5:
            report += "âœ… Small project detected. Good for initial testing.\n"
        else:
            report += f"ğŸ“ˆ Large project detected ({source_count} files). Consider modular testing.\n"
        
        if header_count == 0:
            report += "âš ï¸  No header files found. Check include paths.\n"
        else:
            report += f"âœ… Found {header_count} header files for dependency analysis.\n"
        
        mock_count = self._count_mock_headers()
        if mock_count > 0:
            report += f"âœ… Successfully generated {mock_count} mock headers.\n"
        else:
            report += "âš ï¸  No mocks generated. Check LLM connectivity and dependencies.\n"
        
        # Coverage-specific recommendations
        coverage_data = input_data.get_coverage_data()
        if coverage_data and "error" not in coverage_data:
            coverage_pct = coverage_data.get("coverage_percentage", 0.0)
            
            if coverage_pct >= 80:
                report += "ğŸ¯ Excellent coverage! Consider maintaining this level.\n"
            elif coverage_pct >= 60:
                report += "ğŸ¯ Good coverage. Try to reach 80% for better quality assurance.\n"
            elif coverage_pct >= 40:
                report += "ğŸ¯ Fair coverage. Focus on testing critical code paths.\n"
            else:
                report += "ğŸ¯ Low coverage. Significant testing improvements needed.\n"
            
            if coverage_data.get("lcov_html_dir"):
                report += "ğŸ“Š Review the HTML coverage report for detailed line-by-line analysis.\n"
        
        report += f"\nğŸ¯ Next steps:\n"
        
        if mock_count > 0:
            report += "   - Review generated mocks for accuracy\n"
            report += "   - Compile test code with generated mocks\n"
        
        if coverage_data and "error" not in coverage_data:
            report += "   - Analyze coverage gaps using the generated reports\n"
            report += "   - Add unit tests for uncovered code paths\n"
            report += "   - Run iterative coverage analysis\n"
        else:
            report += "   - Fix compilation issues to enable coverage analysis\n"
            report += "   - Ensure all dependencies are properly mocked\n"
        
        report += "   - Set up continuous integration with coverage tracking\n"
        
        report += f"""
ğŸ“‹ OUTPUT DIRECTORY STRUCTURE:
   output/UnitTestCoverage/
   â”œâ”€â”€ [source_file.cpp]/
   â”‚   â””â”€â”€ [function_name]/
   â”‚       â””â”€â”€ [generated_mocks.h]
   â”œâ”€â”€ coverage_data/
   â”‚   â”œâ”€â”€ build/              (compiled with coverage)
   â”‚   â”œâ”€â”€ lcov_html/          (HTML coverage reports)
   â”‚   â””â”€â”€ coverage.info       (lcov data file)
   â””â”€â”€ coverage_report.txt (this file)

"""
        return report